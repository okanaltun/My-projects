{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "seed(1907)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLOW:\n",
    "\n",
    "In this study, by using the communities dataset, I'd like to build strong models to predict Per Capita Violent Crimes with a wide (but some of them similar !!!) feature set. After data cleaning and organization step, I will start with widely used ML algorithms, Support Vector Machine and finally Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('communities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1994 entries, 0 to 1993\n",
      "Data columns (total 127 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   state                  1994 non-null   int64  \n",
      " 1   county                 820 non-null    float64\n",
      " 2   community              817 non-null    float64\n",
      " 3   communityname          1994 non-null   object \n",
      " 4   population             1994 non-null   float64\n",
      " 5   householdsize          1994 non-null   float64\n",
      " 6   racepctblack           1994 non-null   float64\n",
      " 7   racePctWhite           1994 non-null   float64\n",
      " 8   racePctAsian           1994 non-null   float64\n",
      " 9   racePctHisp            1994 non-null   float64\n",
      " 10  agePct12t21            1994 non-null   float64\n",
      " 11  agePct12t29            1994 non-null   float64\n",
      " 12  agePct16t24            1994 non-null   float64\n",
      " 13  agePct65up             1994 non-null   float64\n",
      " 14  numbUrban              1994 non-null   float64\n",
      " 15  pctUrban               1994 non-null   float64\n",
      " 16  medIncome              1994 non-null   float64\n",
      " 17  pctWWage               1994 non-null   float64\n",
      " 18  pctWFarmSelf           1994 non-null   float64\n",
      " 19  pctWInvInc             1994 non-null   float64\n",
      " 20  pctWSocSec             1994 non-null   float64\n",
      " 21  pctWPubAsst            1994 non-null   float64\n",
      " 22  pctWRetire             1994 non-null   float64\n",
      " 23  medFamInc              1994 non-null   float64\n",
      " 24  perCapInc              1994 non-null   float64\n",
      " 25  whitePerCap            1994 non-null   float64\n",
      " 26  blackPerCap            1994 non-null   float64\n",
      " 27  indianPerCap           1994 non-null   float64\n",
      " 28  AsianPerCap            1994 non-null   float64\n",
      " 29  OtherPerCap            1993 non-null   float64\n",
      " 30  HispPerCap             1994 non-null   float64\n",
      " 31  NumUnderPov            1994 non-null   float64\n",
      " 32  PctPopUnderPov         1994 non-null   float64\n",
      " 33  PctLess9thGrade        1994 non-null   float64\n",
      " 34  PctNotHSGrad           1994 non-null   float64\n",
      " 35  PctBSorMore            1994 non-null   float64\n",
      " 36  PctUnemployed          1994 non-null   float64\n",
      " 37  PctEmploy              1994 non-null   float64\n",
      " 38  PctEmplManu            1994 non-null   float64\n",
      " 39  PctEmplProfServ        1994 non-null   float64\n",
      " 40  PctOccupManu           1994 non-null   float64\n",
      " 41  PctOccupMgmtProf       1994 non-null   float64\n",
      " 42  MalePctDivorce         1994 non-null   float64\n",
      " 43  MalePctNevMarr         1994 non-null   float64\n",
      " 44  FemalePctDiv           1994 non-null   float64\n",
      " 45  TotalPctDiv            1994 non-null   float64\n",
      " 46  PersPerFam             1994 non-null   float64\n",
      " 47  PctFam2Par             1994 non-null   float64\n",
      " 48  PctKids2Par            1994 non-null   float64\n",
      " 49  PctYoungKids2Par       1994 non-null   float64\n",
      " 50  PctTeen2Par            1994 non-null   float64\n",
      " 51  PctWorkMomYoungKids    1994 non-null   float64\n",
      " 52  PctWorkMom             1994 non-null   float64\n",
      " 53  NumIlleg               1994 non-null   float64\n",
      " 54  PctIlleg               1994 non-null   float64\n",
      " 55  NumImmig               1994 non-null   float64\n",
      " 56  PctImmigRecent         1994 non-null   float64\n",
      " 57  PctImmigRec5           1994 non-null   float64\n",
      " 58  PctImmigRec8           1994 non-null   float64\n",
      " 59  PctImmigRec10          1994 non-null   float64\n",
      " 60  PctRecentImmig         1994 non-null   float64\n",
      " 61  PctRecImmig5           1994 non-null   float64\n",
      " 62  PctRecImmig8           1994 non-null   float64\n",
      " 63  PctRecImmig10          1994 non-null   float64\n",
      " 64  PctSpeakEnglOnly       1994 non-null   float64\n",
      " 65  PctNotSpeakEnglWell    1994 non-null   float64\n",
      " 66  PctLargHouseFam        1994 non-null   float64\n",
      " 67  PctLargHouseOccup      1994 non-null   float64\n",
      " 68  PersPerOccupHous       1994 non-null   float64\n",
      " 69  PersPerOwnOccHous      1994 non-null   float64\n",
      " 70  PersPerRentOccHous     1994 non-null   float64\n",
      " 71  PctPersOwnOccup        1994 non-null   float64\n",
      " 72  PctPersDenseHous       1994 non-null   float64\n",
      " 73  PctHousLess3BR         1994 non-null   float64\n",
      " 74  MedNumBR               1994 non-null   float64\n",
      " 75  HousVacant             1994 non-null   float64\n",
      " 76  PctHousOccup           1994 non-null   float64\n",
      " 77  PctHousOwnOcc          1994 non-null   float64\n",
      " 78  PctVacantBoarded       1994 non-null   float64\n",
      " 79  PctVacMore6Mos         1994 non-null   float64\n",
      " 80  MedYrHousBuilt         1994 non-null   float64\n",
      " 81  PctHousNoPhone         1994 non-null   float64\n",
      " 82  PctWOFullPlumb         1994 non-null   float64\n",
      " 83  OwnOccLowQuart         1994 non-null   float64\n",
      " 84  OwnOccMedVal           1994 non-null   float64\n",
      " 85  OwnOccHiQuart          1994 non-null   float64\n",
      " 86  RentLowQ               1994 non-null   float64\n",
      " 87  RentMedian             1994 non-null   float64\n",
      " 88  RentHighQ              1994 non-null   float64\n",
      " 89  MedRent                1994 non-null   float64\n",
      " 90  MedRentPctHousInc      1994 non-null   float64\n",
      " 91  MedOwnCostPctInc       1994 non-null   float64\n",
      " 92  MedOwnCostPctIncNoMtg  1994 non-null   float64\n",
      " 93  NumInShelters          1994 non-null   float64\n",
      " 94  NumStreet              1994 non-null   float64\n",
      " 95  PctForeignBorn         1994 non-null   float64\n",
      " 96  PctBornSameState       1994 non-null   float64\n",
      " 97  PctSameHouse85         1994 non-null   float64\n",
      " 98  PctSameCity85          1994 non-null   float64\n",
      " 99  PctSameState85         1994 non-null   float64\n",
      " 100 LemasSwornFT           319 non-null    float64\n",
      " 101 LemasSwFTPerPop        319 non-null    float64\n",
      " 102 LemasSwFTFieldOps      319 non-null    float64\n",
      " 103 LemasSwFTFieldPerPop   319 non-null    float64\n",
      " 104 LemasTotalReq          319 non-null    float64\n",
      " 105 LemasTotReqPerPop      319 non-null    float64\n",
      " 106 PolicReqPerOffic       319 non-null    float64\n",
      " 107 PolicPerPop            319 non-null    float64\n",
      " 108 RacialMatchCommPol     319 non-null    float64\n",
      " 109 PctPolicWhite          319 non-null    float64\n",
      " 110 PctPolicBlack          319 non-null    float64\n",
      " 111 PctPolicHisp           319 non-null    float64\n",
      " 112 PctPolicAsian          319 non-null    float64\n",
      " 113 PctPolicMinor          319 non-null    float64\n",
      " 114 OfficAssgnDrugUnits    319 non-null    float64\n",
      " 115 NumKindsDrugsSeiz      319 non-null    float64\n",
      " 116 PolicAveOTWorked       319 non-null    float64\n",
      " 117 LandArea               1994 non-null   float64\n",
      " 118 PopDens                1994 non-null   float64\n",
      " 119 PctUsePubTrans         1994 non-null   float64\n",
      " 120 PolicCars              319 non-null    float64\n",
      " 121 PolicOperBudg          319 non-null    float64\n",
      " 122 LemasPctPolicOnPatr    319 non-null    float64\n",
      " 123 LemasGangUnitDeploy    319 non-null    float64\n",
      " 124 LemasPctOfficDrugUn    1994 non-null   float64\n",
      " 125 PolicBudgPerPop        319 non-null    float64\n",
      " 126 ViolentCrimesPerPop    1994 non-null   float64\n",
      "dtypes: float64(125), int64(1), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data information is observed, there are 1994 inputs and except from the variable communityname which contain string values, all variables are either float or integer. Variable community name is a non-predictive variable given just for information along with variables state, county, community and fold. \n",
    "\n",
    "These variables, except of 'fold', contain significate number of null values and they should be dropped from the database. \n",
    "\n",
    "Additionally, another interesting observation is that variables contain either no null values or 319 non-null values which might indicate missing information for a mutual reason. These null values should be treated carefully not to lose required information or overpresent the same information in a way that would mislead the model. Also, dropping these variables is a valid option since a large portion of those variables are null.\n",
    "\n",
    "Target: ViolentCrimesPerPop\n",
    "\n",
    "Metric: RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Organization:\n",
    "\n",
    "Aside from columns that contain null values, other variables do not require any type or dummy transformation. After handling null values, correlation among variables should be closely monitored.\n",
    "\n",
    "Columns that contain null values are law enforcement and police related. I examined these variables one by one and most of them are numeric values but LemasGangUnitDeploy is actually ordinal. \n",
    "\n",
    "When I implement data imputation for these variables, I assume that these indicators might have a changing effect among regions but more similar within and depends on the population size as well. Therefore I am going to try assigning state medians for per population variables (not means since outliers for large states might affect the mean) to these columns of states that are null and null county values from its state. Nominal variable along with variables that are not per population ara going to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables are found to be relational with others (per population versions etc.) and are dropped. Others that contain\n",
    "# null are assumed to be correlated (if county) with other counties within that state and median of counties is assigned. \n",
    "\n",
    "# If all inputs are null for a state, then median of states is assigned first. Then if a value is null median of counties of\n",
    "# that specific state is going to be assined. But almost half of county values are null, for those, general median value is \n",
    "# going to be assigned.\n",
    "\n",
    "to_be_dropped = ['LemasSwornFT',\n",
    "                 'LemasSwFTFieldOps',\n",
    "                 'LemasTotalReq',\n",
    "                 'PolicReqPerOffic',\n",
    "                 'PctPolicWhite',\n",
    "                 'PctPolicBlack',\n",
    "                 'PctPolicHisp',\n",
    "                 'PctPolicAsian',\n",
    "                 'OfficAssgnDrugUnits',\n",
    "                 'NumKindsDrugsSeiz',\n",
    "                 'PolicCars',\n",
    "                 'LemasGangUnitDeploy',\n",
    "                 'LemasPctOfficDrugUn',\n",
    "                 'PolicOperBudg']\n",
    "\n",
    "df1 = df.drop(to_be_dropped,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_null_assignment(df,col):\n",
    "    all_median = round(df[col].median(),2)\n",
    "    for st in df.state.unique():\n",
    "        state_median = df[df['state']==st][col].median()\n",
    "        if df[df['state']==st][[col]].isna().values.all():\n",
    "            df[col]= np.where((df[col].isna())&(df['state']==st),all_median, df[col])\n",
    "        else:\n",
    "            df[col]= np.where((df[col].isna())&(df['state']==st),state_median, df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_changed =  ['LemasSwFTPerPop',\n",
    "                  'LemasSwFTFieldPerPop',\n",
    "                  'LemasTotReqPerPop',\n",
    "                  'PolicPerPop',\n",
    "                  'RacialMatchCommPol',\n",
    "                  'PctPolicMinor',\n",
    "                  'PolicAveOTWorked',\n",
    "                  'LemasPctPolicOnPatr',\n",
    "                  'PolicBudgPerPop']\n",
    "\n",
    "# Null variables dropped version is saved to be used for later\n",
    "df2 = df1.drop(to_be_changed,axis=1)\n",
    "for col in to_be_changed:\n",
    "    df1 = state_null_assignment(df1,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1994 entries, 0 to 1993\n",
      "Data columns (total 113 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   state                  1994 non-null   int64  \n",
      " 1   county                 820 non-null    float64\n",
      " 2   community              817 non-null    float64\n",
      " 3   communityname          1994 non-null   object \n",
      " 4   population             1994 non-null   float64\n",
      " 5   householdsize          1994 non-null   float64\n",
      " 6   racepctblack           1994 non-null   float64\n",
      " 7   racePctWhite           1994 non-null   float64\n",
      " 8   racePctAsian           1994 non-null   float64\n",
      " 9   racePctHisp            1994 non-null   float64\n",
      " 10  agePct12t21            1994 non-null   float64\n",
      " 11  agePct12t29            1994 non-null   float64\n",
      " 12  agePct16t24            1994 non-null   float64\n",
      " 13  agePct65up             1994 non-null   float64\n",
      " 14  numbUrban              1994 non-null   float64\n",
      " 15  pctUrban               1994 non-null   float64\n",
      " 16  medIncome              1994 non-null   float64\n",
      " 17  pctWWage               1994 non-null   float64\n",
      " 18  pctWFarmSelf           1994 non-null   float64\n",
      " 19  pctWInvInc             1994 non-null   float64\n",
      " 20  pctWSocSec             1994 non-null   float64\n",
      " 21  pctWPubAsst            1994 non-null   float64\n",
      " 22  pctWRetire             1994 non-null   float64\n",
      " 23  medFamInc              1994 non-null   float64\n",
      " 24  perCapInc              1994 non-null   float64\n",
      " 25  whitePerCap            1994 non-null   float64\n",
      " 26  blackPerCap            1994 non-null   float64\n",
      " 27  indianPerCap           1994 non-null   float64\n",
      " 28  AsianPerCap            1994 non-null   float64\n",
      " 29  OtherPerCap            1993 non-null   float64\n",
      " 30  HispPerCap             1994 non-null   float64\n",
      " 31  NumUnderPov            1994 non-null   float64\n",
      " 32  PctPopUnderPov         1994 non-null   float64\n",
      " 33  PctLess9thGrade        1994 non-null   float64\n",
      " 34  PctNotHSGrad           1994 non-null   float64\n",
      " 35  PctBSorMore            1994 non-null   float64\n",
      " 36  PctUnemployed          1994 non-null   float64\n",
      " 37  PctEmploy              1994 non-null   float64\n",
      " 38  PctEmplManu            1994 non-null   float64\n",
      " 39  PctEmplProfServ        1994 non-null   float64\n",
      " 40  PctOccupManu           1994 non-null   float64\n",
      " 41  PctOccupMgmtProf       1994 non-null   float64\n",
      " 42  MalePctDivorce         1994 non-null   float64\n",
      " 43  MalePctNevMarr         1994 non-null   float64\n",
      " 44  FemalePctDiv           1994 non-null   float64\n",
      " 45  TotalPctDiv            1994 non-null   float64\n",
      " 46  PersPerFam             1994 non-null   float64\n",
      " 47  PctFam2Par             1994 non-null   float64\n",
      " 48  PctKids2Par            1994 non-null   float64\n",
      " 49  PctYoungKids2Par       1994 non-null   float64\n",
      " 50  PctTeen2Par            1994 non-null   float64\n",
      " 51  PctWorkMomYoungKids    1994 non-null   float64\n",
      " 52  PctWorkMom             1994 non-null   float64\n",
      " 53  NumIlleg               1994 non-null   float64\n",
      " 54  PctIlleg               1994 non-null   float64\n",
      " 55  NumImmig               1994 non-null   float64\n",
      " 56  PctImmigRecent         1994 non-null   float64\n",
      " 57  PctImmigRec5           1994 non-null   float64\n",
      " 58  PctImmigRec8           1994 non-null   float64\n",
      " 59  PctImmigRec10          1994 non-null   float64\n",
      " 60  PctRecentImmig         1994 non-null   float64\n",
      " 61  PctRecImmig5           1994 non-null   float64\n",
      " 62  PctRecImmig8           1994 non-null   float64\n",
      " 63  PctRecImmig10          1994 non-null   float64\n",
      " 64  PctSpeakEnglOnly       1994 non-null   float64\n",
      " 65  PctNotSpeakEnglWell    1994 non-null   float64\n",
      " 66  PctLargHouseFam        1994 non-null   float64\n",
      " 67  PctLargHouseOccup      1994 non-null   float64\n",
      " 68  PersPerOccupHous       1994 non-null   float64\n",
      " 69  PersPerOwnOccHous      1994 non-null   float64\n",
      " 70  PersPerRentOccHous     1994 non-null   float64\n",
      " 71  PctPersOwnOccup        1994 non-null   float64\n",
      " 72  PctPersDenseHous       1994 non-null   float64\n",
      " 73  PctHousLess3BR         1994 non-null   float64\n",
      " 74  MedNumBR               1994 non-null   float64\n",
      " 75  HousVacant             1994 non-null   float64\n",
      " 76  PctHousOccup           1994 non-null   float64\n",
      " 77  PctHousOwnOcc          1994 non-null   float64\n",
      " 78  PctVacantBoarded       1994 non-null   float64\n",
      " 79  PctVacMore6Mos         1994 non-null   float64\n",
      " 80  MedYrHousBuilt         1994 non-null   float64\n",
      " 81  PctHousNoPhone         1994 non-null   float64\n",
      " 82  PctWOFullPlumb         1994 non-null   float64\n",
      " 83  OwnOccLowQuart         1994 non-null   float64\n",
      " 84  OwnOccMedVal           1994 non-null   float64\n",
      " 85  OwnOccHiQuart          1994 non-null   float64\n",
      " 86  RentLowQ               1994 non-null   float64\n",
      " 87  RentMedian             1994 non-null   float64\n",
      " 88  RentHighQ              1994 non-null   float64\n",
      " 89  MedRent                1994 non-null   float64\n",
      " 90  MedRentPctHousInc      1994 non-null   float64\n",
      " 91  MedOwnCostPctInc       1994 non-null   float64\n",
      " 92  MedOwnCostPctIncNoMtg  1994 non-null   float64\n",
      " 93  NumInShelters          1994 non-null   float64\n",
      " 94  NumStreet              1994 non-null   float64\n",
      " 95  PctForeignBorn         1994 non-null   float64\n",
      " 96  PctBornSameState       1994 non-null   float64\n",
      " 97  PctSameHouse85         1994 non-null   float64\n",
      " 98  PctSameCity85          1994 non-null   float64\n",
      " 99  PctSameState85         1994 non-null   float64\n",
      " 100 LemasSwFTPerPop        1994 non-null   float64\n",
      " 101 LemasSwFTFieldPerPop   1994 non-null   float64\n",
      " 102 LemasTotReqPerPop      1994 non-null   float64\n",
      " 103 PolicPerPop            1994 non-null   float64\n",
      " 104 RacialMatchCommPol     1994 non-null   float64\n",
      " 105 PctPolicMinor          1994 non-null   float64\n",
      " 106 PolicAveOTWorked       1994 non-null   float64\n",
      " 107 LandArea               1994 non-null   float64\n",
      " 108 PopDens                1994 non-null   float64\n",
      " 109 PctUsePubTrans         1994 non-null   float64\n",
      " 110 LemasPctPolicOnPatr    1994 non-null   float64\n",
      " 111 PolicBudgPerPop        1994 non-null   float64\n",
      " 112 ViolentCrimesPerPop    1994 non-null   float64\n",
      "dtypes: float64(111), int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['state','county','community','communityname',],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data imputation is done, but these variables are going to be closely monitored during feature selection. First, let's see correlation among variables:\n",
    "\n",
    "As it can bee seen variables are not strongly correlated except from some groups which we know from variable explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23ab9861438>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('RedGreenRed', ['crimson', 'lime', 'crimson'])\n",
    "corr = df1.corr()\n",
    "sns.heatmap(corr, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumIlleg</th>\n",
       "      <th>PctIlleg</th>\n",
       "      <th>NumImmig</th>\n",
       "      <th>PctImmigRecent</th>\n",
       "      <th>PctImmigRec5</th>\n",
       "      <th>PctImmigRec8</th>\n",
       "      <th>PctImmigRec10</th>\n",
       "      <th>PctRecentImmig</th>\n",
       "      <th>PctRecImmig5</th>\n",
       "      <th>PctRecImmig8</th>\n",
       "      <th>PctRecImmig10</th>\n",
       "      <th>PctSpeakEnglOnly</th>\n",
       "      <th>PctNotSpeakEnglWell</th>\n",
       "      <th>PctLargHouseFam</th>\n",
       "      <th>PctLargHouseOccup</th>\n",
       "      <th>PersPerOccupHous</th>\n",
       "      <th>PersPerOwnOccHous</th>\n",
       "      <th>PersPerRentOccHous</th>\n",
       "      <th>PctPersOwnOccup</th>\n",
       "      <th>PctPersDenseHous</th>\n",
       "      <th>PctHousLess3BR</th>\n",
       "      <th>MedNumBR</th>\n",
       "      <th>HousVacant</th>\n",
       "      <th>PctHousOccup</th>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <th>RentLowQ</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>RentHighQ</th>\n",
       "      <th>MedRent</th>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LemasSwFTPerPop</th>\n",
       "      <th>LemasSwFTFieldPerPop</th>\n",
       "      <th>LemasTotReqPerPop</th>\n",
       "      <th>PolicPerPop</th>\n",
       "      <th>RacialMatchCommPol</th>\n",
       "      <th>PctPolicMinor</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>0.336264</td>\n",
       "      <td>0.423164</td>\n",
       "      <td>0.064072</td>\n",
       "      <td>0.696269</td>\n",
       "      <td>0.361123</td>\n",
       "      <td>0.558154</td>\n",
       "      <td>0.291570</td>\n",
       "      <td>0.495687</td>\n",
       "      <td>0.471133</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.479248</td>\n",
       "      <td>0.375677</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.368049</td>\n",
       "      <td>0.291098</td>\n",
       "      <td>0.203506</td>\n",
       "      <td>0.322357</td>\n",
       "      <td>0.284742</td>\n",
       "      <td>0.386279</td>\n",
       "      <td>0.055507</td>\n",
       "      <td>0.303024</td>\n",
       "      <td>0.315807</td>\n",
       "      <td>0.383330</td>\n",
       "      <td>0.361675</td>\n",
       "      <td>0.363531</td>\n",
       "      <td>0.501073</td>\n",
       "      <td>0.396384</td>\n",
       "      <td>0.440597</td>\n",
       "      <td>0.391224</td>\n",
       "      <td>0.441339</td>\n",
       "      <td>0.461244</td>\n",
       "      <td>0.434453</td>\n",
       "      <td>0.487568</td>\n",
       "      <td>0.494273</td>\n",
       "      <td>0.487748</td>\n",
       "      <td>0.610918</td>\n",
       "      <td>0.620657</td>\n",
       "      <td>0.664032</td>\n",
       "      <td>0.582884</td>\n",
       "      <td>0.501449</td>\n",
       "      <td>0.526690</td>\n",
       "      <td>0.036294</td>\n",
       "      <td>0.249995</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.320211</td>\n",
       "      <td>0.360622</td>\n",
       "      <td>0.399077</td>\n",
       "      <td>0.427879</td>\n",
       "      <td>0.181364</td>\n",
       "      <td>0.182126</td>\n",
       "      <td>0.184774</td>\n",
       "      <td>0.182879</td>\n",
       "      <td>0.785903</td>\n",
       "      <td>0.150587</td>\n",
       "      <td>0.267608</td>\n",
       "      <td>0.251891</td>\n",
       "      <td>0.462101</td>\n",
       "      <td>0.494428</td>\n",
       "      <td>0.404097</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.186264</td>\n",
       "      <td>0.495186</td>\n",
       "      <td>0.314694</td>\n",
       "      <td>0.076815</td>\n",
       "      <td>0.719549</td>\n",
       "      <td>0.548686</td>\n",
       "      <td>0.204529</td>\n",
       "      <td>0.433335</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.264478</td>\n",
       "      <td>0.243059</td>\n",
       "      <td>0.264689</td>\n",
       "      <td>0.263490</td>\n",
       "      <td>0.268942</td>\n",
       "      <td>0.346379</td>\n",
       "      <td>0.372457</td>\n",
       "      <td>0.422964</td>\n",
       "      <td>0.384102</td>\n",
       "      <td>0.490125</td>\n",
       "      <td>0.449754</td>\n",
       "      <td>0.403816</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.187816</td>\n",
       "      <td>0.223684</td>\n",
       "      <td>0.176108</td>\n",
       "      <td>0.187821</td>\n",
       "      <td>0.704521</td>\n",
       "      <td>0.219656</td>\n",
       "      <td>0.263621</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.726610</td>\n",
       "      <td>0.164942</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.166505</td>\n",
       "      <td>0.179185</td>\n",
       "      <td>0.128256</td>\n",
       "      <td>0.444811</td>\n",
       "      <td>0.209362</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.204108</td>\n",
       "      <td>0.178071</td>\n",
       "      <td>0.173619</td>\n",
       "      <td>0.222137</td>\n",
       "      <td>0.167564</td>\n",
       "      <td>0.198257</td>\n",
       "      <td>0.191109</td>\n",
       "      <td>0.186804</td>\n",
       "      <td>0.171593</td>\n",
       "      <td>0.164775</td>\n",
       "      <td>0.195411</td>\n",
       "      <td>0.191008</td>\n",
       "      <td>0.183081</td>\n",
       "      <td>0.127941</td>\n",
       "      <td>0.228474</td>\n",
       "      <td>0.213360</td>\n",
       "      <td>0.202508</td>\n",
       "      <td>0.209193</td>\n",
       "      <td>0.202171</td>\n",
       "      <td>0.174036</td>\n",
       "      <td>0.202386</td>\n",
       "      <td>0.175457</td>\n",
       "      <td>0.198922</td>\n",
       "      <td>0.186292</td>\n",
       "      <td>0.182460</td>\n",
       "      <td>0.175437</td>\n",
       "      <td>0.175170</td>\n",
       "      <td>0.183607</td>\n",
       "      <td>0.154594</td>\n",
       "      <td>0.201976</td>\n",
       "      <td>0.206353</td>\n",
       "      <td>0.218749</td>\n",
       "      <td>0.191507</td>\n",
       "      <td>0.168612</td>\n",
       "      <td>0.175241</td>\n",
       "      <td>0.108671</td>\n",
       "      <td>0.229946</td>\n",
       "      <td>0.087189</td>\n",
       "      <td>0.219088</td>\n",
       "      <td>0.210924</td>\n",
       "      <td>0.201498</td>\n",
       "      <td>0.194970</td>\n",
       "      <td>0.235792</td>\n",
       "      <td>0.236333</td>\n",
       "      <td>0.236739</td>\n",
       "      <td>0.234822</td>\n",
       "      <td>0.226869</td>\n",
       "      <td>0.219716</td>\n",
       "      <td>0.196567</td>\n",
       "      <td>0.190709</td>\n",
       "      <td>0.169551</td>\n",
       "      <td>0.157924</td>\n",
       "      <td>0.189301</td>\n",
       "      <td>0.197087</td>\n",
       "      <td>0.209956</td>\n",
       "      <td>0.172508</td>\n",
       "      <td>0.255182</td>\n",
       "      <td>0.150465</td>\n",
       "      <td>0.194024</td>\n",
       "      <td>0.185204</td>\n",
       "      <td>0.217770</td>\n",
       "      <td>0.188986</td>\n",
       "      <td>0.232467</td>\n",
       "      <td>0.242847</td>\n",
       "      <td>0.206295</td>\n",
       "      <td>0.224425</td>\n",
       "      <td>0.231542</td>\n",
       "      <td>0.235252</td>\n",
       "      <td>0.219323</td>\n",
       "      <td>0.209278</td>\n",
       "      <td>0.248286</td>\n",
       "      <td>0.213404</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.187274</td>\n",
       "      <td>0.192593</td>\n",
       "      <td>0.102607</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.081697</td>\n",
       "      <td>0.085414</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>0.081703</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.126104</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.129174</td>\n",
       "      <td>0.082189</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "count  1994.000000    1994.000000   1994.000000   1994.000000   1994.000000   \n",
       "mean      0.057593       0.463395      0.179629      0.753716      0.153681   \n",
       "std       0.126906       0.163717      0.253442      0.244039      0.208877   \n",
       "min       0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%       0.010000       0.350000      0.020000      0.630000      0.040000   \n",
       "50%       0.020000       0.440000      0.060000      0.850000      0.070000   \n",
       "75%       0.050000       0.540000      0.230000      0.940000      0.170000   \n",
       "max       1.000000       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       racePctHisp  agePct12t21  agePct12t29  agePct16t24   agePct65up  \\\n",
       "count  1994.000000  1994.000000  1994.000000  1994.000000  1994.000000   \n",
       "mean      0.144022     0.424218     0.493867     0.336264     0.423164   \n",
       "std       0.232492     0.155196     0.143564     0.166505     0.179185   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.010000     0.340000     0.410000     0.250000     0.300000   \n",
       "50%       0.040000     0.400000     0.480000     0.290000     0.420000   \n",
       "75%       0.160000     0.470000     0.540000     0.360000     0.530000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         numbUrban     pctUrban    medIncome     pctWWage  pctWFarmSelf  \\\n",
       "count  1994.000000  1994.000000  1994.000000  1994.000000   1994.000000   \n",
       "mean      0.064072     0.696269     0.361123     0.558154      0.291570   \n",
       "std       0.128256     0.444811     0.209362     0.182913      0.204108   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       0.000000     0.000000     0.200000     0.440000      0.160000   \n",
       "50%       0.030000     1.000000     0.320000     0.560000      0.230000   \n",
       "75%       0.070000     1.000000     0.490000     0.690000      0.370000   \n",
       "max       1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "        pctWInvInc   pctWSocSec  pctWPubAsst   pctWRetire    medFamInc  \\\n",
       "count  1994.000000  1994.000000  1994.000000  1994.000000  1994.000000   \n",
       "mean      0.495687     0.471133     0.317778     0.479248     0.375677   \n",
       "std       0.178071     0.173619     0.222137     0.167564     0.198257   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.370000     0.350000     0.142500     0.360000     0.230000   \n",
       "50%       0.480000     0.475000     0.260000     0.470000     0.330000   \n",
       "75%       0.620000     0.580000     0.440000     0.580000     0.480000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         perCapInc  whitePerCap  blackPerCap  indianPerCap  AsianPerCap  \\\n",
       "count  1994.000000  1994.000000  1994.000000   1994.000000  1994.000000   \n",
       "mean      0.350251     0.368049     0.291098      0.203506     0.322357   \n",
       "std       0.191109     0.186804     0.171593      0.164775     0.195411   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.220000     0.240000     0.172500      0.110000     0.190000   \n",
       "50%       0.300000     0.320000     0.250000      0.170000     0.280000   \n",
       "75%       0.430000     0.440000     0.380000      0.250000     0.400000   \n",
       "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       OtherPerCap   HispPerCap  NumUnderPov  PctPopUnderPov  PctLess9thGrade  \\\n",
       "count  1993.000000  1994.000000  1994.000000     1994.000000      1994.000000   \n",
       "mean      0.284742     0.386279     0.055507        0.303024         0.315807   \n",
       "std       0.191008     0.183081     0.127941        0.228474         0.213360   \n",
       "min       0.000000     0.000000     0.000000        0.000000         0.000000   \n",
       "25%       0.170000     0.260000     0.010000        0.110000         0.160000   \n",
       "50%       0.250000     0.345000     0.020000        0.250000         0.270000   \n",
       "75%       0.360000     0.480000     0.050000        0.450000         0.420000   \n",
       "max       1.000000     1.000000     1.000000        1.000000         1.000000   \n",
       "\n",
       "       PctNotHSGrad  PctBSorMore  PctUnemployed    PctEmploy  PctEmplManu  \\\n",
       "count   1994.000000  1994.000000    1994.000000  1994.000000  1994.000000   \n",
       "mean       0.383330     0.361675       0.363531     0.501073     0.396384   \n",
       "std        0.202508     0.209193       0.202171     0.174036     0.202386   \n",
       "min        0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%        0.230000     0.210000       0.220000     0.380000     0.250000   \n",
       "50%        0.360000     0.310000       0.320000     0.510000     0.370000   \n",
       "75%        0.510000     0.460000       0.480000     0.627500     0.520000   \n",
       "max        1.000000     1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "       PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  MalePctDivorce  \\\n",
       "count      1994.000000   1994.000000       1994.000000     1994.000000   \n",
       "mean          0.440597      0.391224          0.441339        0.461244   \n",
       "std           0.175457      0.198922          0.186292        0.182460   \n",
       "min           0.000000      0.000000          0.000000        0.000000   \n",
       "25%           0.320000      0.240000          0.310000        0.330000   \n",
       "50%           0.410000      0.370000          0.400000        0.470000   \n",
       "75%           0.530000      0.510000          0.540000        0.590000   \n",
       "max           1.000000      1.000000          1.000000        1.000000   \n",
       "\n",
       "       MalePctNevMarr  FemalePctDiv  TotalPctDiv   PersPerFam   PctFam2Par  \\\n",
       "count     1994.000000   1994.000000  1994.000000  1994.000000  1994.000000   \n",
       "mean         0.434453      0.487568     0.494273     0.487748     0.610918   \n",
       "std          0.175437      0.175170     0.183607     0.154594     0.201976   \n",
       "min          0.000000      0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.310000      0.360000     0.360000     0.400000     0.490000   \n",
       "50%          0.400000      0.500000     0.500000     0.470000     0.630000   \n",
       "75%          0.500000      0.620000     0.630000     0.560000     0.760000   \n",
       "max          1.000000      1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       PctKids2Par  PctYoungKids2Par  PctTeen2Par  PctWorkMomYoungKids  \\\n",
       "count  1994.000000       1994.000000  1994.000000          1994.000000   \n",
       "mean      0.620657          0.664032     0.582884             0.501449   \n",
       "std       0.206353          0.218749     0.191507             0.168612   \n",
       "min       0.000000          0.000000     0.000000             0.000000   \n",
       "25%       0.490000          0.530000     0.480000             0.390000   \n",
       "50%       0.640000          0.700000     0.610000             0.510000   \n",
       "75%       0.780000          0.840000     0.720000             0.620000   \n",
       "max       1.000000          1.000000     1.000000             1.000000   \n",
       "\n",
       "        PctWorkMom     NumIlleg     PctIlleg     NumImmig  PctImmigRecent  \\\n",
       "count  1994.000000  1994.000000  1994.000000  1994.000000     1994.000000   \n",
       "mean      0.526690     0.036294     0.249995     0.030060        0.320211   \n",
       "std       0.175241     0.108671     0.229946     0.087189        0.219088   \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.420000     0.000000     0.090000     0.000000        0.160000   \n",
       "50%       0.540000     0.010000     0.170000     0.010000        0.290000   \n",
       "75%       0.650000     0.020000     0.320000     0.020000        0.430000   \n",
       "max       1.000000     1.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "       PctImmigRec5  PctImmigRec8  PctImmigRec10  PctRecentImmig  \\\n",
       "count   1994.000000   1994.000000    1994.000000     1994.000000   \n",
       "mean       0.360622      0.399077       0.427879        0.181364   \n",
       "std        0.210924      0.201498       0.194970        0.235792   \n",
       "min        0.000000      0.000000       0.000000        0.000000   \n",
       "25%        0.200000      0.250000       0.280000        0.030000   \n",
       "50%        0.340000      0.390000       0.430000        0.090000   \n",
       "75%        0.480000      0.530000       0.560000        0.230000   \n",
       "max        1.000000      1.000000       1.000000        1.000000   \n",
       "\n",
       "       PctRecImmig5  PctRecImmig8  PctRecImmig10  PctSpeakEnglOnly  \\\n",
       "count   1994.000000   1994.000000    1994.000000       1994.000000   \n",
       "mean       0.182126      0.184774       0.182879          0.785903   \n",
       "std        0.236333      0.236739       0.234822          0.226869   \n",
       "min        0.000000      0.000000       0.000000          0.000000   \n",
       "25%        0.030000      0.030000       0.030000          0.730000   \n",
       "50%        0.080000      0.090000       0.090000          0.870000   \n",
       "75%        0.230000      0.230000       0.230000          0.940000   \n",
       "max        1.000000      1.000000       1.000000          1.000000   \n",
       "\n",
       "       PctNotSpeakEnglWell  PctLargHouseFam  PctLargHouseOccup  \\\n",
       "count          1994.000000      1994.000000        1994.000000   \n",
       "mean              0.150587         0.267608           0.251891   \n",
       "std               0.219716         0.196567           0.190709   \n",
       "min               0.000000         0.000000           0.000000   \n",
       "25%               0.030000         0.150000           0.140000   \n",
       "50%               0.060000         0.200000           0.190000   \n",
       "75%               0.160000         0.310000           0.290000   \n",
       "max               1.000000         1.000000           1.000000   \n",
       "\n",
       "       PersPerOccupHous  PersPerOwnOccHous  PersPerRentOccHous  \\\n",
       "count       1994.000000        1994.000000         1994.000000   \n",
       "mean           0.462101           0.494428            0.404097   \n",
       "std            0.169551           0.157924            0.189301   \n",
       "min            0.000000           0.000000            0.000000   \n",
       "25%            0.340000           0.390000            0.270000   \n",
       "50%            0.440000           0.480000            0.360000   \n",
       "75%            0.550000           0.580000            0.490000   \n",
       "max            1.000000           1.000000            1.000000   \n",
       "\n",
       "       PctPersOwnOccup  PctPersDenseHous  PctHousLess3BR     MedNumBR  \\\n",
       "count      1994.000000       1994.000000     1994.000000  1994.000000   \n",
       "mean          0.562598          0.186264        0.495186     0.314694   \n",
       "std           0.197087          0.209956        0.172508     0.255182   \n",
       "min           0.000000          0.000000        0.000000     0.000000   \n",
       "25%           0.440000          0.060000        0.400000     0.000000   \n",
       "50%           0.560000          0.110000        0.510000     0.500000   \n",
       "75%           0.700000          0.220000        0.600000     0.500000   \n",
       "max           1.000000          1.000000        1.000000     1.000000   \n",
       "\n",
       "        HousVacant  PctHousOccup  PctHousOwnOcc  PctVacantBoarded  \\\n",
       "count  1994.000000   1994.000000    1994.000000       1994.000000   \n",
       "mean      0.076815      0.719549       0.548686          0.204529   \n",
       "std       0.150465      0.194024       0.185204          0.217770   \n",
       "min       0.000000      0.000000       0.000000          0.000000   \n",
       "25%       0.010000      0.630000       0.430000          0.060000   \n",
       "50%       0.030000      0.770000       0.540000          0.130000   \n",
       "75%       0.070000      0.860000       0.670000          0.270000   \n",
       "max       1.000000      1.000000       1.000000          1.000000   \n",
       "\n",
       "       PctVacMore6Mos  MedYrHousBuilt  PctHousNoPhone  PctWOFullPlumb  \\\n",
       "count     1994.000000     1994.000000     1994.000000     1994.000000   \n",
       "mean         0.433335        0.494178        0.264478        0.243059   \n",
       "std          0.188986        0.232467        0.242847        0.206295   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.290000        0.350000        0.060000        0.100000   \n",
       "50%          0.420000        0.520000        0.185000        0.190000   \n",
       "75%          0.560000        0.670000        0.420000        0.330000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       OwnOccLowQuart  OwnOccMedVal  OwnOccHiQuart     RentLowQ   RentMedian  \\\n",
       "count     1994.000000   1994.000000    1994.000000  1994.000000  1994.000000   \n",
       "mean         0.264689      0.263490       0.268942     0.346379     0.372457   \n",
       "std          0.224425      0.231542       0.235252     0.219323     0.209278   \n",
       "min          0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "25%          0.090000      0.090000       0.090000     0.170000     0.200000   \n",
       "50%          0.180000      0.170000       0.180000     0.310000     0.330000   \n",
       "75%          0.400000      0.390000       0.380000     0.490000     0.520000   \n",
       "max          1.000000      1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "         RentHighQ      MedRent  MedRentPctHousInc  MedOwnCostPctInc  \\\n",
       "count  1994.000000  1994.000000        1994.000000       1994.000000   \n",
       "mean      0.422964     0.384102           0.490125          0.449754   \n",
       "std       0.248286     0.213404           0.169500          0.187274   \n",
       "min       0.000000     0.000000           0.000000          0.000000   \n",
       "25%       0.220000     0.210000           0.370000          0.320000   \n",
       "50%       0.370000     0.340000           0.480000          0.450000   \n",
       "75%       0.590000     0.530000           0.590000          0.580000   \n",
       "max       1.000000     1.000000           1.000000          1.000000   \n",
       "\n",
       "       MedOwnCostPctIncNoMtg  NumInShelters    NumStreet  PctForeignBorn  \\\n",
       "count            1994.000000    1994.000000  1994.000000     1994.000000   \n",
       "mean                0.403816       0.029438     0.022778        0.215552   \n",
       "std                 0.192593       0.102607     0.100400        0.231134   \n",
       "min                 0.000000       0.000000     0.000000        0.000000   \n",
       "25%                 0.250000       0.000000     0.000000        0.060000   \n",
       "50%                 0.370000       0.000000     0.000000        0.130000   \n",
       "75%                 0.510000       0.010000     0.000000        0.280000   \n",
       "max                 1.000000       1.000000     1.000000        1.000000   \n",
       "\n",
       "       PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "count       1994.000000     1994.000000    1994.000000     1994.000000   \n",
       "mean           0.608892        0.535050       0.626424        0.651530   \n",
       "std            0.204329        0.181352       0.200521        0.198221   \n",
       "min            0.000000        0.000000       0.000000        0.000000   \n",
       "25%            0.470000        0.420000       0.520000        0.560000   \n",
       "50%            0.630000        0.540000       0.670000        0.700000   \n",
       "75%            0.777500        0.660000       0.770000        0.790000   \n",
       "max            1.000000        1.000000       1.000000        1.000000   \n",
       "\n",
       "       LemasSwFTPerPop  LemasSwFTFieldPerPop  LemasTotReqPerPop  PolicPerPop  \\\n",
       "count      1994.000000           1994.000000        1994.000000  1994.000000   \n",
       "mean          0.187816              0.223684           0.176108     0.187821   \n",
       "std           0.081697              0.085414           0.082729     0.081703   \n",
       "min           0.000000              0.000000           0.000000     0.000000   \n",
       "25%           0.140000              0.160000           0.135000     0.140000   \n",
       "50%           0.185000              0.225000           0.155000     0.185000   \n",
       "75%           0.210000              0.260000           0.190000     0.210000   \n",
       "max           1.000000              1.000000           1.000000     1.000000   \n",
       "\n",
       "       RacialMatchCommPol  PctPolicMinor  PolicAveOTWorked     LandArea  \\\n",
       "count         1994.000000    1994.000000       1994.000000  1994.000000   \n",
       "mean             0.704521       0.219656          0.263621     0.065231   \n",
       "std              0.143222       0.139706          0.126104     0.109459   \n",
       "min              0.000000       0.000000          0.000000     0.000000   \n",
       "25%              0.590000       0.115000          0.180000     0.020000   \n",
       "50%              0.730000       0.190000          0.230000     0.040000   \n",
       "75%              0.800000       0.300000          0.350000     0.070000   \n",
       "max              1.000000       1.000000          1.000000     1.000000   \n",
       "\n",
       "           PopDens  PctUsePubTrans  LemasPctPolicOnPatr  PolicBudgPerPop  \\\n",
       "count  1994.000000     1994.000000          1994.000000      1994.000000   \n",
       "mean      0.232854        0.161685             0.726610         0.164942   \n",
       "std       0.203092        0.229055             0.129174         0.082189   \n",
       "min       0.000000        0.000000             0.000000         0.000000   \n",
       "25%       0.100000        0.020000             0.700000         0.110000   \n",
       "50%       0.170000        0.070000             0.750000         0.160000   \n",
       "75%       0.280000        0.190000             0.780000         0.190000   \n",
       "max       1.000000        1.000000             1.000000         1.000000   \n",
       "\n",
       "       ViolentCrimesPerPop  \n",
       "count          1994.000000  \n",
       "mean              0.237979  \n",
       "std               0.232985  \n",
       "min               0.000000  \n",
       "25%               0.070000  \n",
       "50%               0.150000  \n",
       "75%               0.330000  \n",
       "max               1.000000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "df1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One value was empty for this column :)\n",
    "\n",
    "df1['OtherPerCap'].fillna(0,inplace=True)\n",
    "df1.to_pickle('final_data.pkl')\n",
    "\n",
    "X = df1.copy().drop('ViolentCrimesPerPop',axis=1)\n",
    "y = df1['ViolentCrimesPerPop']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Really basic decision tree and random forest regressors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.04023547094188377\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(criterion = 'mse')\n",
    "\n",
    "clf = clf.fit(train_x, train_y)\n",
    "y_pred1 = clf.predict(test_x)\n",
    "\n",
    "print('RMSE: ',mean_squared_error(test_y, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.017011882805611226\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=100, max_features=10)\n",
    "\n",
    "rfc = rfc.fit(train_x, train_y)\n",
    "y_pred1 = rfc.predict(test_x)\n",
    "\n",
    "print('RMSE: ',mean_squared_error(test_y, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.017679354102171963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okana\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svcf = svm.LinearSVR()\n",
    "svcf.fit(train_x,train_y)\n",
    "y_pred = svcf.predict(test_x)\n",
    "\n",
    "\n",
    "print(\"RMSE: \", mean_squared_error(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Trials: \n",
    "\n",
    "Here, I will try different NN Models with different optimizers, activation functions, layers etc. Whilst trying those, firstly, higher batch size and  lower number of epochs are chosen to save time. Later on, with the final model, epoch and batch size will be optimized as well. In the last case, the model will be tried with the dataset without the variables that went thorough imputation (df2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we are working with regression for a target variable between 0-1, either mse or binary_crossentropy is most useful as the loss function. Initially, I am going to work with mse, but the final model will be tested with binary_crossentropy as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also, for the reason specified above, sigmoid is going to be utilized as the last layer activation function for this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside from these, different optimizers with various hyperparameters, number of layers and neurons and activation functions are going to be tried. Initially, I have chosen Adams as the optimizer based on my previous experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(network, num_epoch, size):\n",
    "    \n",
    "    network.fit(train_x, train_y, epochs = num_epoch, batch_size = size)\n",
    "    nn_pred = network.predict(test_x)\n",
    "\n",
    "    print (\"RMSE:\", mean_squared_error(test_y, nn_pred))    \n",
    "    \n",
    "    return mean_squared_error(test_y, nn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "RMSE: 0.016640675706989592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016640675706989592"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(250,  activation='selu'))\n",
    "network.add(layers.Dense(150, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try with additional layers and different number of neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "RMSE: 0.015958158512176007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015958158512176007"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best performing so far:\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "RMSE: 0.016718961617348437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016718961617348437"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(125,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "RMSE: 0.017282542511783086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017282542511783086"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(100,  activation='selu'))\n",
    "network.add(layers.Dense(25, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try another optimizer: Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "RMSE: 0.01866751153956107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01866751153956107"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adagrad(learning_rate=0.01, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0444 - mse: 0.0444\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0330 - mse: 0.0330\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0257 - mse: 0.0257\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "RMSE: 0.017657592242014374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017657592242014374"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With different learning rate:\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adagrad(learning_rate=0.001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 50, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It did not show significant improvement: lets try Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0919 - mse: 0.0919\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0852 - mse: 0.0852\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0771 - mse: 0.0771\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0697 - mse: 0.0697\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0643 - mse: 0.0643\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0550 - mse: 0.0550\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0486 - mse: 0.0486\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0469 - mse: 0.0469\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0412\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0381\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0372 - mse: 0.0372\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0363\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0355 - mse: 0.0355\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0347 - mse: 0.0347\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0340 - mse: 0.0340\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0327 - mse: 0.0327\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0316 - mse: 0.0316\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0311 - mse: 0.0311\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0297 - mse: 0.0297\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0286 - mse: 0.0286\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0283 - mse: 0.0283\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0277 - mse: 0.0277\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0272 - mse: 0.0272\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0267 - mse: 0.0267\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "RMSE: 0.020208779323656438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020208779323656438"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adadelta(learning_rate=0.001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1388 - mse: 0.1388\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0430\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0333 - mse: 0.0333\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0277 - mse: 0.0277\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0248 - mse: 0.0248\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "RMSE: 0.017397551778631296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017397551778631296"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With different learning rate:\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adadelta(learning_rate=0.01, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0123 - mse: 0.0123\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120A: 0s - loss: 0.0123 - mse: 0.0\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "RMSE: 0.017340958127609322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017340958127609322"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With different learning rate:\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adadelta(learning_rate=0.1, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even with greater number of epochs and smaller batch size, no improvement with Adadelta as well, lets try RMSprop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1162 - mse: 0.1162\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.1157\n",
      "RMSE: 0.09644408817635272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09644408817635272"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.1, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0762 - mse: 0.0762\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "RMSE: 0.016328408481651194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016328408481651194"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different learning rate:\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar results with Adams, lets try different neuron structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0937 - mse: 0.0937\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0275 - mse: 0.0275\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0217 - mse: 0.0217A: 0s - loss: 0.0215 - mse: 0.021\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144A: 0s - loss: 0.0145 - mse: 0.014\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "RMSE: 0.016726743468810167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016726743468810167"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(125,  activation='selu'))\n",
    "network.add(layers.Dense(100,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0714 - mse: 0.0714\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 965us/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 996us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 967us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 981us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 977us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 939us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 993us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 977us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 973us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 957us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 948us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 940us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 985us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 983us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 981us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 979us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 954us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 948us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 944us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 941us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 958us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 946us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 945us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 941us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 963us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 957us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 981us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 950us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 957us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 951us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 940us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 966us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 971us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "RMSE: 0.01634610235988587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01634610235988587"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0918 - mse: 0.0918\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0293\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "RMSE: 0.01635172009513418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01635172009513418"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(250,  activation='selu'))\n",
    "network.add(layers.Dense(100, activation='selu'))\n",
    "network.add(layers.Dense(50, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0330 - mse: 0.0330\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 985us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 991us/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 993us/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 993us/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 986us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 997us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1000us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 997us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1000us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 994us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 973us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 991us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 998us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 993us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 978us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 973us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 999us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 989us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 979us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 991us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 948us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 956us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 959us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 987us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 993us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 941us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 944us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 986us/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 961us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 966us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 986us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 966us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 946us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 986us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 922us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 940us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 913us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 924us/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 934us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 911us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 928us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 969us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 926us/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 944us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 911us/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 997us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 936us/step - loss: 0.0154 - mse: 0.0154\n",
      "RMSE: 0.01587084918627268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01587084918627268"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(125,  activation='selu'))\n",
    "network.add(layers.Dense(100, activation='selu'))\n",
    "network.add(layers.Dense(50, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0978 - mse: 0.0978\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0299 - mse: 0.0299\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 991us/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 986us/step - loss: 0.0227 - mse: 0.0227\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 979us/step - loss: 0.0218 - mse: 0.0218\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 987us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 985us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 964us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 997us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 964us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 975us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 974us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 965us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 965us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 987us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 986us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 999us/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 962us/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 957us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 997us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 970us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 927us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 933us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 936us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 967us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1000us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 990us/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 962us/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 969us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 949us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 993us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 920us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 924us/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0158 - mse: 0.015 - 0s 1ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 965us/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 927us/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 952us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 966us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 934us/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 926us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 915us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 920us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 964us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 898us/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 991us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 956us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 977us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 977us/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 976us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 931us/step - loss: 0.0143 - mse: 0.0143\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 926us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 929us/step - loss: 0.0144 - mse: 0.0144\n",
      "RMSE: 0.0160947792598437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0160947792598437"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(100,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(50, activation='selu'))\n",
    "network.add(layers.Dense(25, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall it does not beat Adams significantly even with greater epoch and smaller batch size, lets try SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 959us/step - loss: 0.0977 - mse: 0.0977\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 975us/step - loss: 0.0917 - mse: 0.0917\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 957us/step - loss: 0.0867 - mse: 0.0867\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 944us/step - loss: 0.0824 - mse: 0.0824\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0788 - mse: 0.0788\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 925us/step - loss: 0.0757 - mse: 0.0757\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 977us/step - loss: 0.0731 - mse: 0.0731\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 911us/step - loss: 0.0707 - mse: 0.0707\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0688 - mse: 0.0688\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0670 - mse: 0.0670\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0655 - mse: 0.0655\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 944us/step - loss: 0.0641 - mse: 0.0641\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0629 - mse: 0.0629\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.0619 - mse: 0.0619\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 991us/step - loss: 0.0609 - mse: 0.0609\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0601 - mse: 0.0601\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 0.0593 - mse: 0.0593\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 904us/step - loss: 0.0586 - mse: 0.0586\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 931us/step - loss: 0.0580 - mse: 0.0580\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 904us/step - loss: 0.0574 - mse: 0.0574\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.0569 - mse: 0.0569\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 874us/step - loss: 0.0565 - mse: 0.0565\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.0560 - mse: 0.0560\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 904us/step - loss: 0.0556 - mse: 0.0556\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 929us/step - loss: 0.0553 - mse: 0.0553\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 853us/step - loss: 0.0549 - mse: 0.0549\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 896us/step - loss: 0.0546 - mse: 0.0546\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 889us/step - loss: 0.0543 - mse: 0.0543\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 964us/step - loss: 0.0540 - mse: 0.0540\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 898us/step - loss: 0.0537 - mse: 0.0537\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 887us/step - loss: 0.0535 - mse: 0.0535\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0532 - mse: 0.0532\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 929us/step - loss: 0.0530 - mse: 0.0530\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 999us/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 873us/step - loss: 0.0526 - mse: 0.0526\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 869us/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 875us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 882us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 862us/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 875us/step - loss: 0.0517 - mse: 0.0517\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 915us/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 860us/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 895us/step - loss: 0.0512 - mse: 0.0512\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 875us/step - loss: 0.0511 - mse: 0.0511\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 879us/step - loss: 0.0509 - mse: 0.0509\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 879us/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 882us/step - loss: 0.0507 - mse: 0.0507\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 918us/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 878us/step - loss: 0.0504 - mse: 0.0504\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 884us/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 880us/step - loss: 0.0501 - mse: 0.0501\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 875us/step - loss: 0.0500 - mse: 0.0500\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 931us/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 885us/step - loss: 0.0498 - mse: 0.0498\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 889us/step - loss: 0.0496 - mse: 0.0496\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0494 - mse: 0.0494\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 853us/step - loss: 0.0493 - mse: 0.0493\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0492 - mse: 0.0492\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 912us/step - loss: 0.0491 - mse: 0.0491\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 826us/step - loss: 0.0490 - mse: 0.0490\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 876us/step - loss: 0.0489 - mse: 0.0489\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 874us/step - loss: 0.0487 - mse: 0.0487\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 903us/step - loss: 0.0486 - mse: 0.0486\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 889us/step - loss: 0.0485 - mse: 0.0485\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0484 - mse: 0.0484\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 929us/step - loss: 0.0483 - mse: 0.0483\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 910us/step - loss: 0.0482 - mse: 0.0482\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0448 - mse: 0.044 - 0s 948us/step - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 901us/step - loss: 0.0480 - mse: 0.0480\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 838us/step - loss: 0.0477 - mse: 0.0477\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0476 - mse: 0.0476\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0475 - mse: 0.0475\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 864us/step - loss: 0.0474 - mse: 0.0474\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0473 - mse: 0.0473\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0472 - mse: 0.0472\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 884us/step - loss: 0.0471 - mse: 0.0471\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0470 - mse: 0.0470\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0469 - mse: 0.0469\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 891us/step - loss: 0.0468 - mse: 0.0468\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 918us/step - loss: 0.0467 - mse: 0.0467\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0466 - mse: 0.0466\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 911us/step - loss: 0.0465 - mse: 0.0465\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 838us/step - loss: 0.0464 - mse: 0.0464\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 898us/step - loss: 0.0463 - mse: 0.0463\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 911us/step - loss: 0.0462 - mse: 0.0462\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 818us/step - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 971us/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0459 - mse: 0.0459\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 904us/step - loss: 0.0458 - mse: 0.0458\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 950us/step - loss: 0.0457 - mse: 0.0457\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0456\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 891us/step - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 984us/step - loss: 0.0454 - mse: 0.0454\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 904us/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 846us/step - loss: 0.0452 - mse: 0.0452\n",
      "RMSE: 0.038206462411096896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.038206462411096896"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(100,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(50, activation='selu'))\n",
    "network.add(layers.Dense(25, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.SGD(learning_rate=0.00001)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "299/299 [==============================] - 0s 977us/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0318 - mse: 0.0318\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 0s 957us/step - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 0s 954us/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 0s 922us/step - loss: 0.0247 - mse: 0.0247\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 0s 945us/step - loss: 0.0237 - mse: 0.0237\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 0s 941us/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 0s 957us/step - loss: 0.0227 - mse: 0.0227 0s - loss: 0.0228 - mse: 0\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 0s 983us/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 0s 964us/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 0s 951us/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 0s 986us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 0s 934us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 0s 971us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 0s 877us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 0s 885us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 0s 844us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 0s 861us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 0s 885us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 0s 901us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 0s 867us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 0s 849us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 28/100\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 29/100\n",
      "299/299 [==============================] - 0s 866us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 30/100\n",
      "299/299 [==============================] - 0s 861us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 31/100\n",
      "299/299 [==============================] - 0s 863us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 32/100\n",
      "299/299 [==============================] - 0s 868us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 33/100\n",
      "299/299 [==============================] - 0s 872us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 34/100\n",
      "299/299 [==============================] - 0s 858us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 35/100\n",
      "299/299 [==============================] - 0s 836us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 36/100\n",
      "299/299 [==============================] - 0s 862us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 37/100\n",
      "299/299 [==============================] - 0s 861us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 38/100\n",
      "299/299 [==============================] - 0s 873us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 39/100\n",
      "299/299 [==============================] - 0s 857us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 40/100\n",
      "299/299 [==============================] - 0s 867us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 41/100\n",
      "299/299 [==============================] - 0s 836us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 42/100\n",
      "299/299 [==============================] - 0s 872us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 43/100\n",
      "299/299 [==============================] - 0s 845us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 44/100\n",
      "299/299 [==============================] - 0s 868us/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 45/100\n",
      "299/299 [==============================] - 0s 862us/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 46/100\n",
      "299/299 [==============================] - 0s 857us/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 47/100\n",
      "299/299 [==============================] - 0s 868us/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 48/100\n",
      "299/299 [==============================] - 0s 888us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 49/100\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 50/100\n",
      "299/299 [==============================] - 0s 882us/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 51/100\n",
      "299/299 [==============================] - 0s 888us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 52/100\n",
      "299/299 [==============================] - 0s 871us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 53/100\n",
      "299/299 [==============================] - 0s 895us/step - loss: 0.0181 - mse: 0.0181\n",
      "Epoch 54/100\n",
      "299/299 [==============================] - 0s 871us/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 55/100\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 56/100\n",
      "299/299 [==============================] - 0s 872us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 57/100\n",
      "299/299 [==============================] - 0s 841us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 58/100\n",
      "299/299 [==============================] - 0s 846us/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 59/100\n",
      "299/299 [==============================] - 0s 843us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 60/100\n",
      "299/299 [==============================] - 0s 839us/step - loss: 0.0178 - mse: 0.0178\n",
      "Epoch 61/100\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 62/100\n",
      "299/299 [==============================] - 0s 841us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 63/100\n",
      "299/299 [==============================] - 0s 870us/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 64/100\n",
      "299/299 [==============================] - 0s 868us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 65/100\n",
      "299/299 [==============================] - 0s 839us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 66/100\n",
      "299/299 [==============================] - 0s 876us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 67/100\n",
      "299/299 [==============================] - 0s 875us/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 68/100\n",
      "299/299 [==============================] - 0s 850us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 69/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 70/100\n",
      "299/299 [==============================] - 0s 957us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 71/100\n",
      "299/299 [==============================] - 0s 911us/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 72/100\n",
      "299/299 [==============================] - 0s 910us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 73/100\n",
      "299/299 [==============================] - 0s 895us/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 74/100\n",
      "299/299 [==============================] - 0s 865us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 75/100\n",
      "299/299 [==============================] - 0s 862us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 76/100\n",
      "299/299 [==============================] - 0s 880us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 77/100\n",
      "299/299 [==============================] - 0s 873us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 78/100\n",
      "299/299 [==============================] - 0s 888us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 79/100\n",
      "299/299 [==============================] - 0s 913us/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 80/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 81/100\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 82/100\n",
      "299/299 [==============================] - 0s 971us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 83/100\n",
      "299/299 [==============================] - 0s 873us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 84/100\n",
      "299/299 [==============================] - 0s 881us/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 85/100\n",
      "299/299 [==============================] - 0s 881us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 86/100\n",
      "299/299 [==============================] - 0s 847us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 87/100\n",
      "299/299 [==============================] - 0s 817us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 88/100\n",
      "299/299 [==============================] - 0s 894us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 89/100\n",
      "299/299 [==============================] - 0s 859us/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 90/100\n",
      "299/299 [==============================] - 0s 855us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 91/100\n",
      "299/299 [==============================] - 0s 853us/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 92/100\n",
      "299/299 [==============================] - 0s 854us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 93/100\n",
      "299/299 [==============================] - 0s 855us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 94/100\n",
      "299/299 [==============================] - 0s 944us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 95/100\n",
      "299/299 [==============================] - 0s 911us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 96/100\n",
      "299/299 [==============================] - 0s 866us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 97/100\n",
      "299/299 [==============================] - 0s 857us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 98/100\n",
      "299/299 [==============================] - 0s 854us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 99/100\n",
      "299/299 [==============================] - 0s 885us/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 100/100\n",
      "299/299 [==============================] - 0s 885us/step - loss: 0.0166 - mse: 0.0166\n",
      "RMSE: 0.016331999287428133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016331999287428133"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.SGD(learning_rate=0.001)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far, no optimizer has beaten Adams, lets continue with that and try adjustments on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(150,  activation='selu'))\n",
    "network.add(layers.Dense(75, activation='selu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0530 - mse: 0.0530\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0298 - mse: 0.0298\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "RMSE: 0.01571275705272471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01571275705272471"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relu seems better:\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is small, so lets try no batch by setting batch size=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1495/1495 [==============================] - 1s 935us/step - loss: 0.0280 - mse: 0.0280\n",
      "Epoch 2/20\n",
      "1495/1495 [==============================] - 1s 805us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 3/20\n",
      "1495/1495 [==============================] - 1s 826us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 4/20\n",
      "1495/1495 [==============================] - 1s 811us/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 5/20\n",
      "1495/1495 [==============================] - 1s 811us/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 6/20\n",
      "1495/1495 [==============================] - 1s 810us/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 7/20\n",
      "1495/1495 [==============================] - 1s 813us/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 8/20\n",
      "1495/1495 [==============================] - 1s 818us/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 9/20\n",
      "1495/1495 [==============================] - 1s 825us/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 10/20\n",
      "1495/1495 [==============================] - 1s 815us/step - loss: 0.0154 - mse: 0.0154 1s - lo\n",
      "Epoch 11/20\n",
      "1495/1495 [==============================] - 1s 814us/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 12/20\n",
      "1495/1495 [==============================] - 1s 947us/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 13/20\n",
      "1495/1495 [==============================] - 1s 874us/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 14/20\n",
      "1495/1495 [==============================] - 1s 845us/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 15/20\n",
      "1495/1495 [==============================] - 1s 843us/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 16/20\n",
      "1495/1495 [==============================] - 1s 847us/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 17/20\n",
      "1495/1495 [==============================] - 1s 876us/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 18/20\n",
      "1495/1495 [==============================] - 1s 949us/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 19/20\n",
      "1495/1495 [==============================] - 1s 943us/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 20/20\n",
      "1495/1495 [==============================] - 1s 895us/step - loss: 0.0110 - mse: 0.0110\n",
      "RMSE: 0.01724397219578467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01724397219578467"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not 1 but 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0379 - mse: 0.0379\n",
      "Epoch 2/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 3/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 4/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 5/20\n",
      "299/299 [==============================] - 0s 989us/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 6/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 7/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 8/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 9/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 10/20\n",
      "299/299 [==============================] - 0s 992us/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 11/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 12/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 13/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 14/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 15/20\n",
      "299/299 [==============================] - 0s 997us/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 16/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 17/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 18/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 19/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 20/20\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "RMSE: 0.016092324143828135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016092324143828135"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "RMSE: 0.015499581180733244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015499581180733244"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets increase layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0575 - mse: 0.0575\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0241\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0130\n",
      "RMSE: 0.01812546147669597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01812546147669597"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(125,  activation='relu'))\n",
    "network.add(layers.Dense(100,  activation='relu'))\n",
    "network.add(layers.Dense(100,  activation='relu'))\n",
    "network.add(layers.Dense(75,  activation='relu'))\n",
    "network.add(layers.Dense(75,  activation='relu'))\n",
    "network.add(layers.Dense(50, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/150 [..............................] - ETA: 0s - loss: 0.1444 - mse: 0.1444WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0112s). Check your callbacks.\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0605 - mse: 0.0605\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188A: 0s - loss: 0.0193 - mse: 0.0\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - mse: 0.0138\n",
      "RMSE: 0.016404804890947904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016404804890947904"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(125,  activation='relu'))\n",
    "network.add(layers.Dense(75,  activation='relu'))\n",
    "network.add(layers.Dense(50, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial layers & neurons were optimal, lets try that with greater number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0547 - mse: 0.0547\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 0.0185A: 0s - loss: 0.0195 - mse: 0.01\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0153A: 0s - loss: 0.0147 - mse: 0.01\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0150 - mse: 0.0150\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0138\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 1000us/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032A: 0s - loss: 0.0032 - mse: 0.0\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032 \n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030 \n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 \n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 \n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 \n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 \n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 \n",
      "Epoch 147/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 \n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 \n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 157/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 \n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "Epoch 162/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "Epoch 163/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 165/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012  \n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 \n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.8855e-04 - mse: 9.8855e-04\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 1000us/step - loss: 9.6184e-04 - mse: 9.6184e-04\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 998us/step - loss: 9.8754e-04 - mse: 9.8754e-04\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 \n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010   \n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 \n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010  \n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.9568e-04 - mse: 9.9568e-04\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011  \n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 9.9543e-04 - mse: 9.9543e-04\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.2331e-04 - mse: 9.2331e-04\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010  \n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.8830e-04 - mse: 9.8830e-04\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 7.7015e-04 - mse: 7.7015e-04\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.3520e-04 - mse: 9.3520e-04\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.5995e-04 - mse: 9.5995e-04\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013  \n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 \n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.5729e-04 - mse: 9.5729e-04\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 8.1106e-04 - mse: 8.1106e-04\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 8.0476e-04 - mse: 8.0476e-04\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.2061e-04 - mse: 9.2061e-04\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.0534e-04 - mse: 9.0534e-04\n",
      "RMSE: 0.022905188271791672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022905188271791672"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0505 - mse: 0.0505\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0231 - mse: 0.0231\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "RMSE: 0.017720541239983442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017720541239983442"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0647 - mse: 0.0647\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0306 - mse: 0.0306\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0128 - mse: 0.0128\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044\n",
      "RMSE: 0.01965443633053583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01965443633053583"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(75, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 100, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176\n",
      "RMSE: 0.01588039837255645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01588039837255645"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(108, input_dim=108, activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(150,  activation='relu'))\n",
    "network.add(layers.Dense(125,  activation='relu'))\n",
    "network.add(layers.Dense(75,  activation='relu'))\n",
    "network.add(layers.Dense(50, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = optimizers.Adam(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "network.compile(optimizer=opt,\n",
    "loss='mse',\n",
    "metrics=['mse'])\n",
    "\n",
    "nn_model(network, 10, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
